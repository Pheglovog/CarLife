部署任何node之前，必须要自定义其配置文件。

| peer    | core.yaml    |
| ------- | ------------ |
| orderer | orderer.yaml |
修改配置的三个方式：
- 修改yaml文件
- 使用环境变量覆盖
- 在CLI命令上指定标志

环境变量和yaml选项的对应关系：

| core.yaml的peer.localMSPid       | CORE_PEER_LOCALMSPID       |
| ------------------------------- | -------------------------- |
| orderer.yaml的General.LocalMSPID | ORDERER_GENERAL_LOCALMSPID |

# 创建peer

peer的core.yaml文件需要自定义或者使用环境变量覆盖。

core.yaml中的参数很多，但其实我们只需要自定义其中的一小部分。如果字段不需要更改，那么就保留默认值。

## Planning for a production peer

### 生成peer identities和MSP

- 文件结构要一致 [folder structure](https://hyperledger-fabric-ca.readthedocs.io/en/latest/deployguide/use_CA.html#folder-structure-for-your-org-and-node-admin-identities)
- 启用tls

### State database
couchdb：查询灵活
leveldb： 性能该，嵌入到项目中

### Sizing your peer resources

一个peer要有多个相关联的container：
- peer coantainer
- couchdb container（optional）
- chaincode launcher container（optional）：部署chaincode container的container
- chaincode container

### Storage considerations


| 配置项                 | 用途                      |
| ------------------- | ----------------------- |
| peer.fileSystemPath | 指定chaincode和ledger存储的地方 |
| peer.mspConfigPath  | 指定identity和MSP存储的地方     |
最佳实践是将这两个参数指定的位置挂载到docker中

ledger.state.stateDatabase ：指定使用couchdb还是leveldb作为状态数据库

### 高可用性

我们要增加部分的冗余节点，方便peer的停机维护

client需要使用service discovery方式，确保将transaction提交给可用的节点

### 监控

须要对所有的区块链节点都仔细监控，账本不断增大，我们可以看到存储空间不够的node以及时为其分配空间。 同时对于负载较大的peer，需要为其增加cpu和内存

### chaincode

在fabric2.0之前，build和launch chaincode是peer的一部分，但是现在改变了，我们可以使用外部的builder和launcher来扩展peer

### Gossip
通过gossip， peer可以以可扩展的方式广播ledger和channel data

启动gossip需要进行的4个配置：
- 前三个在core.yaml中
	- `peer.gossip.bootstrap`, 
	- `peer.gossip.endpoint`, 
	- `peer.gossip.externalEndpoint`
- 第四个在channel configuration中设置org的anchor peer，让org之间可以进行gossip


在fabric2.2之后，我们从orderer中获得block，需要进行下面的配置：

| 配置项                                    | 值     |
| -------------------------------------- | ----- |
| peer.gossip.useLeaderElection          | false |
| peer.gossip.orgLeader                  | true  |
| peer.gossip.state.enabled              | false |
| peer.deliveryclient.blockGossipEnabled | false |
如果所有节点都设置 orgLeader=true （推荐），那么每个节点都会从排序服务中获取区块。


### 服务发现
fabric 的服务发现可以找到运行良好的peer作为背书节点。
服务发现需要启动gossip


## core.yaml的配置项
[Checklist for a production peer — Hyperledger Fabric Docs main documentation](https://hyperledger-fabric.readthedocs.io/en/latest/deploypeer/peerchecklist.html)

## Deploy the peer


# Creating an ordering node

peer和orderer的区别：多个orderer协同工作，构成channel的ordering service/ consenter set

对于orderer集群，我们需要在node level和cluster level都进行配置。cluster level的配置一部分在orderer.yaml中，另一部分在configtx.yaml中

## Planning for an ordering service

### 生成orderer identity 和 MSP

使用fabric CA给每个orderer不同的tls 证书和 org证书

我们先创建的排序节点由一个org拥有，之后其他的组织也可以贡献orderer


### 文件夹管理
保持一致性

### TLS
启用TLS

### Sizing your ordering node resources

orderer没有state database和chaincode，所以orderer其实只有一个container。

如果一个channel使用了orderer作为consenter set，那么他就有该channel的block chain

一个orderer可以加入多个channel，但是逻辑上，每个channel有独一无二的consenter set。

由于一个orderer加入channel的数量不一致，所以其负载也不同，所需的CPU和内存自然也不同。同时，由于raft排序，leader执行排序和验证功能，其他follower只是复制，所以leader的负载更高。

### Cluster considerations

raft集群中只要过半节点正常，那么ordering service就可以运行

raft中，更多的节点意味着更大的通信开销，因为领导者必须与所有节点通信才能使排序服务正常运行
如果一个节点认为它与领导者失去了连接，即使这种通信损失只是由于网络或处理延迟造成的，它也会触发领导者选举。不必要的领导者选举只会增加领导者的通信开销，从而逐渐增加集群的负担。

我们在布局的时候，一个consenter set中的orderer数量最好不要超过50个，一般选用3，5，7，9

### Storage considerations and monitoring
要监视每个orderer的负载情况，当负载增加，CPU资源和内存资源也需要增加

# orderer.yaml的配置项
[Checklist for a production ordering node — Hyperledger Fabric Docs main documentation](https://hyperledger-fabric.readthedocs.io/en/latest/deployorderer/ordererchecklist.html#)

# Deploy the ordering service

## 先决条件
在启动ordering service之前，需要确保已经：
- 创建并组织必要的证书
- 生成创世块
- 配置好orderer.yaml
### Certificates
假设我们的文件结构是这样的：
![image.png](https://mypictures-1308119878.cos.ap-shanghai.myqcloud.com/Obsidian_notebook/202410091713047.png)

需要生成以下证书：
- orderer org MSP
- orderer TLS CA certificates
- orderer local MSP

#### TLS certificates
为了能够启动订购节点，需要进行一些操作：
- 复制TLS CA root certificate（一般名字为ca-cert.pem） . 复制到`organizations/ordererOrganizations/ordererOrg1.example.com/msp/tlscacerts/tls-cert.pem`.
- 复制org CA root certifacate，复制到`organizations/ordererOrganizations/ordererOrg1.example.com/msp/cacerts/ca-cert.pem`.
- 当enroll该orderer的TLS identidy时，public key会放到signcerts， private key放到keystore中，需要将private key重命名为`orderer0-tls-key.pem`，然后将这一对key放入`organizations/ordererOrganizations/ordererOrg1.example.com/orderers/orderer0.ordererOrg1.example.com/tls`
- 在orderer.yaml中,`General.TLS.Certificate` and `General.TLS.PrivateKey`要分别指向public key和private key

如果要使用NodeOU，还需要config.yaml，分别放入org MSP和local MSP中

#### Orderer local MSP

需要将org的MSP复制到`Organizations/ordererOrganizations/ordererOrg1.example.com/orderers/orderer0.ordererOrg1.example.com/msp`中。此路径对应于 orderer.yaml 文件中 General.LocalMSPDir 参数的值。

  
请注意，本地 MSP 包含订购者的签名证书（公钥）和私钥。私钥由节点用来签署交易，因此不被共享，并且必须受到保护。为了获得最大的安全性，可以配置硬件安全模块 (HSM) 来生成并存储此私钥。

### Storage
需要为leger提供持久化存储，默认位置是 `/var/hyperledger/production/orderer`. 也可以通过`orderer.yaml`中的`FileLedger`指定新的位置

### Configuration of orderer.yaml

我们应该改动下面的值：
- General.ListenAddress - 排序节点侦听的主机名。
- General.ListenPort - 排序节点侦听的端口。
- General.TLS.Enabled：true - 应在所有生产网络中启用服务器端 TLS。
- General.TLS.PrivateKey - TLS CA给orderer的private key 。
- General.TLS.Certificate - TLS CA给orderer的public key
- General.TLS.RootCAS - 不设置该值
- General.LocalMSPDir - 排序节点 MSP 文件夹的路径。
- FileLedger.Location - orderer所在channel的账本位置
- ChannelParticipation.Enabled - 设置为 true。这允许排序者加入到应用程序通道（请注意，自 Fabric v3.0 起不再支持系统通道）。


- Admin.ListenAddress - 该orderer admin server的地址。osnadmin命令需要使用该地址来配置ordering service的channel
- Admin.TLS.Enabled： - 从技术上讲，可以将其设置为 false，但不建议这样做。一般来说，您应该始终将此值设置为 true。
- Admin.TLS.PrivateKey：- TLS CA 颁发的orderer 的private key
- Admin.TLS.Certificate: - TLS CA 颁发的orderer的public key
- Admin.TLS.ClientAuthRequired: 该值必须设置为 true。请注意，虽然orderer admin endpoint上的所有操作都需要Mutual TLS，但整个网络不需要使用Mutual TLS。
- Admin.TLS.ClientRootCAs： - 管理客户端 TLS CA 根证书的路径和文件名。在上面的文件夹结构中，这是 admin-client/client-tls-ca-cert.pem。

